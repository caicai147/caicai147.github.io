---
layout: post
title: Python爬虫简介
categories: python之基础 python之网络爬虫
tags: python 爬虫
---

参考[静觅](http://cuiqingcai.com/)>>[Python爬虫入门一之综述](http://cuiqingcai.com/1052.html)

##简介

使用的Python版本是2.7，Python3请另寻其他博文

网络爬虫，又称为网络蜘蛛、网络机器人，在FOAF社区中间，更经常的称为网页追逐着，是一种按照一定的规则，自动的抓取万维网信息的程序或者脚本

要学习Python爬虫，我们要学习的共有以下几点

* Python基础知识
* Python中的urllib和urllib2库的用法
* Python正则表达式
* Python爬虫框架Scrapy
* Python爬虫更高级的功能

##Python基础教程

Python的基础教程学习可以在网上找到很多的资源：

* [慕课网Python教程](http://www.imooc.com/view/177)
* [廖雪峰Python教程](http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000)
* [简明Python教程](http://woodpecker.org.cn/abyteofpython_cn/chinese/pr01.html#s01)

##Python的urllib和urllib2库

urllib和urllib2库是学习Python爬虫最基本的库，利用这个库我们可以得到网页的内容，并对内容用正则表达式提取分析，得到我们想要的结果

##Python正则表达式

Python正则表达式是一种用来匹配字符串的强有力的武器。它的设计思想是用一种描述性的语言来对字符串定义一个规则，凡是符合规则的字符串，我们就认为它“匹配”了，否则，该字符串就是不合法的

##爬虫框架Scrapy

如果你是一个Python高手，基本的爬虫知识都已经掌握了，那么就寻觅一下Python框架吧，Scrapy就是其中一个，这个框架的强大的功能可以参考其官方介绍：

* HTML, XML源数据选择及提取的内置支持
* 提供了一系列在spider之间共享的可复用的过滤器(即 Item Loaders)，对智能处理爬取数据提供了内置支持。
* 通过 feed导出 提供了多格式(JSON、CSV、XML)，多存储后端(FTP、S3、本地文件系统)的内置支持
* 提供了media pipeline，可以自动下载爬取到的数据中的图片(或者其他资源)。
* 高扩展性。您可以通过使用 signals，设计好的API(中间件, extensions, pipelines)来定制实现您的功能。
* 内置的中间件及扩展为下列功能提供了支持:
	* cookies and session 处理
	* HTTP 压缩
	* HTTP 认证
	* HTTP 缓存
	* user-agent模拟
	* robots.txt
	* 爬取深度限制
* 针对非英语语系中不标准或者错误的编码声明, 提供了自动检测以及健壮的编码支持。
* 支持根据模板生成爬虫。在加速爬虫创建的同时，保持在大型项目中的代码更为一致。详细内容请参阅 genspider 命令。
* 针对多爬虫下性能评估、失败检测，提供了可扩展的状态收集工具 。
* 提供 交互式shell终端 , 为您测试XPath表达式，编写和调试爬虫提供了极大的方便
* 提供 System service, 简化在生产环境的部署及运行
* 内置 Web service, 使您可以监视及控制您的机器
* 内置 Telnet终端 ，通过在Scrapy进程中钩入Python终端，使您可以查看并且调试爬虫
* Logging 为您在爬取过程中捕捉错误提供了方便
* 支持 Sitemaps 爬取
* 具有缓存的DNS解析器

官方文档：[http://doc.scrapy.org/en/latest/](http://doc.scrapy.org/en/latest/)

不过还是等到将基础知识学得差不多啦再来用这个Scrapy框架吧

##什么是爬虫

爬虫，即网络爬虫，大家可以理解为在网络上爬行的一只蜘蛛，互联网就比作是一张大网，而爬虫便是在这张网上爬来爬去的蜘蛛咯，如果它遇到资源，那么它就会抓取下来。想抓取什么？这个由你来控制它喽

比如它在抓取一只网页，在这个网中它发现了一条道路，其实就是指向网页的超链接，那么它就可以爬到另一张网上来获取数据。这样，整个连在一起的大网对这只大蜘蛛来说就触手可及了

##浏览网页的过程

在用户浏览网页的过程中，我们可能会看到许多好看的图片，比如[http://image.baidu.com/](http://image.baidu.com/)，我们会看到几张的图片以及百度的搜索框，这个过程其实就是用户输入网址之后，经过DNS服务器，找到服务器主机，向服务器发出请求，服务器经过解析之后，发送给用户的浏览器HTML、JS、CSS等文件，浏览器解析出来，用户便可以看到形形色色的图片了

因此，用户看到的网页实质是有HTML代码构成的，爬虫爬来的便是这些内容，通过分析和过滤这个HTML代码，实现对图片、文字等资源的获取

##URL的含义

URL，即统一资源定位符，也就是我们说的网址，统一资源定位符是对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址。互联网上的每个文件都有一个唯一的URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它。

URL的格式由三部分组成：

* 第一部分是协议(或称为服务方式)。
* 第二部分是存有该资源的主机IP地址(有时也包括端口号)。
* 第三部分是主机资源的具体地址，如目录和文件名等。

爬虫爬取数据时必须要有一个目标的URL才可以获取数据，因此，它是爬虫获取数据的基本依据，准确理解它的含义对爬虫学习有很大帮助。
